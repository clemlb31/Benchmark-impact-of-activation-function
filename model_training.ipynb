{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from brevage_sales import brevage_preprocessing, Brevage_model\n",
    "from animal10 import animals10_preprocessing, Animals10_model\n",
    "from training_functions import train_model\n",
    "# mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_datasets = [\"rockyt07/stock-market-sensex-nifty-all-time-dataset\",\n",
    "            \"minahilfatima12328/performance-trends-in-education\",\n",
    "            \"alessiocorrado99/animals10\",\n",
    "            \"sebastianwillmann/beverage-sales\"]\n",
    "data_dir = \"data/\"\n",
    "\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download:\n",
    "    !mkdir -p {data_dir}\n",
    "    for dataset in kaggle_datasets:\n",
    "        if not os.path.exists(os.path.join(data_dir, dataset.split(\"/\")[-1])):    \n",
    "            !mkdir -p {data_dir/dataset}\n",
    "            !kaggle datasets download -d {dataset} -p {data_dir}/{dataset} --unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist download\n",
    "(mnist_X_train_full, mnist_y_train_full), (mnist_X_test, mnist_y_test) = (keras.datasets.mnist.load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brevage_df = pd.read_csv('./data/sebastianwillmann/beverage-sales/synthetic_beverage_sales_data.csv')\n",
    "# on ne garde que 1 000 000 lignes\n",
    "brevage_df = brevage_df.sample(n=1000000, random_state=42).reset_index(drop=True)\n",
    "train_dataset, val_dataset, test_dataset = brevage_preprocessing(brevage_df,test_size=0.2,val_size=0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Brevage_model(train_dataset.count_features(), mode='relu').to(device)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Epoch 1/50, Training Loss: 79944.4404, Validation Loss: 15027.3685\n",
      "Epoch 2/50, Training Loss: 5480.7439, Validation Loss: 3053.0740\n",
      "Epoch 3/50, Training Loss: 2753.1905, Validation Loss: 2522.0291\n",
      "Epoch 4/50, Training Loss: 2126.0622, Validation Loss: 1823.0052\n",
      "Epoch 5/50, Training Loss: 1378.7503, Validation Loss: 1030.2340\n",
      "Epoch 6/50, Training Loss: 676.3966, Validation Loss: 462.8135\n",
      "Epoch 7/50, Training Loss: 364.1133, Validation Loss: 284.6931\n",
      "Epoch 8/50, Training Loss: 264.0679, Validation Loss: 265.5199\n",
      "Epoch 9/50, Training Loss: 213.8418, Validation Loss: 190.7018\n",
      "Epoch 10/50, Training Loss: 181.9879, Validation Loss: 163.1285\n",
      "Epoch 11/50, Training Loss: 164.4441, Validation Loss: 150.3543\n",
      "Epoch 12/50, Training Loss: 145.7959, Validation Loss: 143.1860\n",
      "Epoch 13/50, Training Loss: 132.6470, Validation Loss: 137.4848\n",
      "Epoch 14/50, Training Loss: 122.3203, Validation Loss: 106.6841\n",
      "Epoch 15/50, Training Loss: 115.3542, Validation Loss: 123.3352\n",
      "Epoch 16/50, Training Loss: 105.2308, Validation Loss: 93.9607\n",
      "Epoch 17/50, Training Loss: 103.1228, Validation Loss: 89.0578\n",
      "Epoch 18/50, Training Loss: 97.3747, Validation Loss: 89.4639\n",
      "Epoch 19/50, Training Loss: 93.6117, Validation Loss: 94.9529\n",
      "Epoch 20/50, Training Loss: 87.9794, Validation Loss: 75.4400\n",
      "Epoch 21/50, Training Loss: 83.7224, Validation Loss: 102.6331\n",
      "Epoch 22/50, Training Loss: 81.9728, Validation Loss: 79.5542\n",
      "Epoch 23/50, Training Loss: 79.8875, Validation Loss: 71.1192\n",
      "Epoch 24/50, Training Loss: 78.2348, Validation Loss: 73.9870\n",
      "Epoch 25/50, Training Loss: 76.1648, Validation Loss: 64.1333\n",
      "Epoch 26/50, Training Loss: 76.0214, Validation Loss: 83.6565\n",
      "Epoch 27/50, Training Loss: 71.8940, Validation Loss: 88.8891\n",
      "Epoch 28/50, Training Loss: 70.4587, Validation Loss: 68.3417\n",
      "Epoch 29/50, Training Loss: 70.1420, Validation Loss: 66.7660\n",
      "Epoch 30/50, Training Loss: 69.4798, Validation Loss: 63.5803\n",
      "Epoch 31/50, Training Loss: 65.2996, Validation Loss: 62.1986\n",
      "Epoch 32/50, Training Loss: 65.2607, Validation Loss: 60.9734\n",
      "Epoch 33/50, Training Loss: 61.7115, Validation Loss: 70.6407\n",
      "Epoch 34/50, Training Loss: 59.9718, Validation Loss: 53.3392\n",
      "Epoch 35/50, Training Loss: 58.6977, Validation Loss: 64.5581\n",
      "Epoch 36/50, Training Loss: 57.3218, Validation Loss: 49.9357\n",
      "Epoch 37/50, Training Loss: 56.4923, Validation Loss: 50.8420\n",
      "Epoch 38/50, Training Loss: 54.9939, Validation Loss: 53.1960\n",
      "Epoch 39/50, Training Loss: 55.6721, Validation Loss: 55.7665\n",
      "Epoch 40/50, Training Loss: 52.6355, Validation Loss: 52.2079\n",
      "Epoch 41/50, Training Loss: 53.6967, Validation Loss: 54.5569\n",
      "Epoch 42/50, Training Loss: 51.2070, Validation Loss: 44.7756\n",
      "Epoch 43/50, Training Loss: 51.0840, Validation Loss: 54.1305\n",
      "Epoch 44/50, Training Loss: 49.9482, Validation Loss: 53.7306\n",
      "Epoch 45/50, Training Loss: 48.2790, Validation Loss: 41.3510\n",
      "Epoch 46/50, Training Loss: 48.2834, Validation Loss: 41.8254\n",
      "Epoch 47/50, Training Loss: 47.3419, Validation Loss: 124.9327\n",
      "Epoch 48/50, Training Loss: 46.8953, Validation Loss: 46.1815\n",
      "Epoch 49/50, Training Loss: 45.4855, Validation Loss: 54.9694\n",
      "Epoch 50/50, Training Loss: 46.3901, Validation Loss: 39.7546\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, criterion, optimizer, num_epochs,train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 38.87211227416992\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(test_dataset.features.to(device)).cpu().detach().numpy()\n",
    "mse = mean_squared_error(test_dataset.targets.numpy(), y_pred)\n",
    "print(f'Test MSE: {mse}')\n",
    "history[\"final_test_loss\"]  = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': [76762.47895996094, 4917.480402141927, 2385.2715601302084, 1355.4028592252605, 546.267305398763, 285.83973342610676, 208.83184728515624, 173.3265512467448, 150.59456974527995, 134.25248311035156, 122.50164867024739, 116.35622235677083, 112.61448102539063, 107.04140088378907, 103.76343618326823, 99.66126768229167, 95.9821802360026, 94.33911462320964, 91.18894970499674, 88.02515171468099, 84.88403221150716, 83.3407439436849, 81.36441092081705, 79.31362923502604, 78.35122577555339, 76.03748635701497, 73.95446583658854, 72.45813270914714, 70.24104186238607, 69.9657667972819, 66.68204318888347, 65.17111615193684, 64.77353048421224, 61.88393656494141, 61.30457855102539, 59.284649084472655, 57.61360815063477, 56.9302004699707, 55.20521035746256, 54.72456991923014, 54.28219326944987, 53.1172882039388, 51.10087702718099, 49.87973960306803, 51.0055470296224, 49.062449031982425, 48.737331572672524, 47.79843918273926, 47.24748483378092, 47.339593358357746], 'val_loss': [13465.639988164063, 2914.677248388672, 2020.126730966797, 859.7517159277344, 348.0061827978516, 249.31306837890625, 183.03603970703125, 168.99719024414063, 155.38307416259767, 132.5958532861328, 110.82461915039063, 114.6704401586914, 103.28105216674804, 107.86752922363281, 112.36643611572265, 101.59821448242188, 93.08128172851562, 96.58714697753906, 93.3948866809082, 93.43490611572265, 121.12905253173828, 82.74691334838867, 88.36350126098633, 76.5272463244629, 86.56338880249024, 71.42747706176758, 72.2322742175293, 63.203406217041014, 66.79248375671386, 67.45659999633789, 98.42414228515625, 72.01400031982422, 65.51931469848633, 66.30700104125977, 62.141632520751955, 66.13957465576172, 61.3926603918457, 54.196544558105465, 70.11938990356445, 60.65900964477539, 70.4341594946289, 45.92481479309082, 50.56885232910156, 45.61439246459961, 45.52363805297851, 47.715461157226564, 43.406188577270505, 43.19055959411621, 39.818945159301755, 48.62687154907226], 'final_test_loss': None, 'activation_function': 'relu', 'training_parameters': {'num_epochs': 50, 'batch_size': 128, 'learning_rate': 0.001}}\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ce que l'on a besoin d'enregistrer\n",
    "# - train loss pour chaque epoch\n",
    "# - val loss pour chaque epoch\n",
    "# - temps d'entrainement\n",
    "# - final test loss\n",
    "# - relu ou gelu\n",
    "# - parameters du modèle (dépend du dataset)\n",
    "# - paramètres d'entrainement :\n",
    "    # - nombre d'epochs\n",
    "    # - batch size\n",
    "    # - learning rate\n",
    "\n",
    "\n",
    "# history = {\n",
    "#     'train_loss': [],\n",
    "#     'val_loss': [],\n",
    "#     'final_test_loss': None,\n",
    "#     'activation_function': 'relu',\n",
    "#     'model_parameters': model.state_dict(),\n",
    "#     'training_parameters': {\n",
    "#         'num_epochs': num_epochs,\n",
    "#         'batch_size': batch_size,\n",
    "#         'learning_rate': learning_rate\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15707 5236 5236\n"
     ]
    }
   ],
   "source": [
    "animals_path = \"data/alessiocorrado99/animals10/raw-img\"\n",
    "train_dataset, val_dataset, test_dataset, class_to_idx, idx_to_class = animals10_preprocessing(animals_path, test_size=0.2, val_size=0.2, image_size=256, random_state=1, subset=1)\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Epoch 1/50, Training Loss: 1.9643, Validation Loss: 1.8303\n",
      "Epoch 2/50, Training Loss: 1.7423, Validation Loss: 1.6657\n",
      "Epoch 3/50, Training Loss: 1.5793, Validation Loss: 1.7456\n",
      "Epoch 4/50, Training Loss: 1.4635, Validation Loss: 1.4875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      8\u001b[39m val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/DL/Benchmark-impact-of-activation-function/training_functions.py:35\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, criterion, optimizer, num_epochs, train_loader, val_loader)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, targets \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[32m     34\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     loss = criterion(outputs, targets)\n\u001b[32m     37\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/DL/Benchmark-impact-of-activation-function/animal10.py:163\u001b[39m, in \u001b[36mAnimals10_model.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m         x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n\u001b[32m    165\u001b[39m         x = \u001b[38;5;28mself\u001b[39m.layer3(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ISF/.venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    533\u001b[39m         F.pad(\n\u001b[32m    534\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    542\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "animal_model = Animals10_model(num_classes=len(class_to_idx), mode='relu').to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 256\n",
    "optimizer = torch.optim.Adam(animal_model.parameters(), lr=learning_rate)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "history = train_model(animal_model, criterion, optimizer, num_epochs,train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Animals10Dataset' object has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y_pred = Brevage_model(\u001b[43mtest_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m.to(device)).cpu().detach().numpy()\n\u001b[32m      2\u001b[39m accuracy = (y_pred.argmax(axis=\u001b[32m1\u001b[39m) == test_dataset.targets.numpy()).mean()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Animals10Dataset' object has no attribute 'features'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
