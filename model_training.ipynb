{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from brevage_sales import brevage_preprocessing\n",
    "from training_functions import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_datasets = [\"rockyt07/stock-market-sensex-nifty-all-time-dataset\",\n",
    "            \"minahilfatima12328/performance-trends-in-education\",\n",
    "            \"alessiocorrado99/animals10\",\n",
    "            \"sebastianwillmann/beverage-sales\"]\n",
    "data_dir = \"data/\"\n",
    "\n",
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download:\n",
    "    !mkdir -p {data_dir}\n",
    "    for dataset in kaggle_datasets:\n",
    "        if not os.path.exists(os.path.join(data_dir, dataset.split(\"/\")[-1])):    \n",
    "            !mkdir -p {data_dir/dataset}\n",
    "            !kaggle datasets download -d {dataset} -p {data_dir}/{dataset} --unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist download\n",
    "(mnist_X_train_full, mnist_y_train_full), (mnist_X_test, mnist_y_test) = (keras.datasets.mnist.load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Order_ID Customer_ID Customer_Type             Product     Category  \\\n",
      "0     ORD1     CUS1496           B2B          Vio Wasser        Water   \n",
      "1     ORD1     CUS1496           B2B               Evian        Water   \n",
      "2     ORD1     CUS1496           B2B              Sprite  Soft Drinks   \n",
      "3     ORD1     CUS1496           B2B  Rauch Multivitamin       Juices   \n",
      "4     ORD1     CUS1496           B2B        Gerolsteiner        Water   \n",
      "\n",
      "   Unit_Price  Quantity  Discount  Total_Price             Region  Order_Date  \n",
      "0        1.66        53      0.10        79.18  Baden-Württemberg  2023-08-23  \n",
      "1        1.56        90      0.10       126.36  Baden-Württemberg  2023-08-23  \n",
      "2        1.17        73      0.05        81.14  Baden-Württemberg  2023-08-23  \n",
      "3        3.22        59      0.10       170.98  Baden-Württemberg  2023-08-23  \n",
      "4        0.87        35      0.10        27.40  Baden-Württemberg  2023-08-23  \n",
      "(8999910, 11)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/sebastianwillmann/beverage-sales/synthetic_beverage_sales_data.csv')\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ne garde que 1 000 000 lignes\n",
    "df = df.sample(n=1000000, random_state=42).reset_index(drop=True)\n",
    "X_train_scaled,X_val_scaled,X_test_scaled,y_train,y_val,y_test = brevage_preprocessing(df,test_size=0.2,val_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brevage_sales import brevage_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = brevage_model(X_train_scaled.shape[1], mode='relu').to(device)\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train_scaled, dtype=torch.float32).to(device), torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1).to(device))\n",
    "val_dataset = TensorDataset(torch.tensor(X_val_scaled, dtype=torch.float32).to(device), torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1).to(device))\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Epoch 1/50, Training Loss: 76762.4790, Validation Loss: 13465.6400\n",
      "Epoch 2/50, Training Loss: 4917.4804, Validation Loss: 2914.6772\n",
      "Epoch 3/50, Training Loss: 2385.2716, Validation Loss: 2020.1267\n",
      "Epoch 4/50, Training Loss: 1355.4029, Validation Loss: 859.7517\n",
      "Epoch 5/50, Training Loss: 546.2673, Validation Loss: 348.0062\n",
      "Epoch 6/50, Training Loss: 285.8397, Validation Loss: 249.3131\n",
      "Epoch 7/50, Training Loss: 208.8318, Validation Loss: 183.0360\n",
      "Epoch 8/50, Training Loss: 173.3266, Validation Loss: 168.9972\n",
      "Epoch 9/50, Training Loss: 150.5946, Validation Loss: 155.3831\n",
      "Epoch 10/50, Training Loss: 134.2525, Validation Loss: 132.5959\n",
      "Epoch 11/50, Training Loss: 122.5016, Validation Loss: 110.8246\n",
      "Epoch 12/50, Training Loss: 116.3562, Validation Loss: 114.6704\n",
      "Epoch 13/50, Training Loss: 112.6145, Validation Loss: 103.2811\n",
      "Epoch 14/50, Training Loss: 107.0414, Validation Loss: 107.8675\n",
      "Epoch 15/50, Training Loss: 103.7634, Validation Loss: 112.3664\n",
      "Epoch 16/50, Training Loss: 99.6613, Validation Loss: 101.5982\n",
      "Epoch 17/50, Training Loss: 95.9822, Validation Loss: 93.0813\n",
      "Epoch 18/50, Training Loss: 94.3391, Validation Loss: 96.5871\n",
      "Epoch 19/50, Training Loss: 91.1889, Validation Loss: 93.3949\n",
      "Epoch 20/50, Training Loss: 88.0252, Validation Loss: 93.4349\n",
      "Epoch 21/50, Training Loss: 84.8840, Validation Loss: 121.1291\n",
      "Epoch 22/50, Training Loss: 83.3407, Validation Loss: 82.7469\n",
      "Epoch 23/50, Training Loss: 81.3644, Validation Loss: 88.3635\n",
      "Epoch 24/50, Training Loss: 79.3136, Validation Loss: 76.5272\n",
      "Epoch 25/50, Training Loss: 78.3512, Validation Loss: 86.5634\n",
      "Epoch 26/50, Training Loss: 76.0375, Validation Loss: 71.4275\n",
      "Epoch 27/50, Training Loss: 73.9545, Validation Loss: 72.2323\n",
      "Epoch 28/50, Training Loss: 72.4581, Validation Loss: 63.2034\n",
      "Epoch 29/50, Training Loss: 70.2410, Validation Loss: 66.7925\n",
      "Epoch 30/50, Training Loss: 69.9658, Validation Loss: 67.4566\n",
      "Epoch 31/50, Training Loss: 66.6820, Validation Loss: 98.4241\n",
      "Epoch 32/50, Training Loss: 65.1711, Validation Loss: 72.0140\n",
      "Epoch 33/50, Training Loss: 64.7735, Validation Loss: 65.5193\n",
      "Epoch 34/50, Training Loss: 61.8839, Validation Loss: 66.3070\n",
      "Epoch 35/50, Training Loss: 61.3046, Validation Loss: 62.1416\n",
      "Epoch 36/50, Training Loss: 59.2846, Validation Loss: 66.1396\n",
      "Epoch 37/50, Training Loss: 57.6136, Validation Loss: 61.3927\n",
      "Epoch 38/50, Training Loss: 56.9302, Validation Loss: 54.1965\n",
      "Epoch 39/50, Training Loss: 55.2052, Validation Loss: 70.1194\n",
      "Epoch 40/50, Training Loss: 54.7246, Validation Loss: 60.6590\n",
      "Epoch 41/50, Training Loss: 54.2822, Validation Loss: 70.4342\n",
      "Epoch 42/50, Training Loss: 53.1173, Validation Loss: 45.9248\n",
      "Epoch 43/50, Training Loss: 51.1009, Validation Loss: 50.5689\n",
      "Epoch 44/50, Training Loss: 49.8797, Validation Loss: 45.6144\n",
      "Epoch 45/50, Training Loss: 51.0055, Validation Loss: 45.5236\n",
      "Epoch 46/50, Training Loss: 49.0624, Validation Loss: 47.7155\n",
      "Epoch 47/50, Training Loss: 48.7373, Validation Loss: 43.4062\n",
      "Epoch 48/50, Training Loss: 47.7984, Validation Loss: 43.1906\n",
      "Epoch 49/50, Training Loss: 47.2475, Validation Loss: 39.8189\n",
      "Epoch 50/50, Training Loss: 47.3396, Validation Loss: 48.6269\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, criterion, optimizer, num_epochs,train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 46.5607867816725\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(torch.tensor(X_test_scaled, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Test MSE: {mse}')\n",
    "history[\"final_test_loss\"]  = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_loss': [76762.47895996094, 4917.480402141927, 2385.2715601302084, 1355.4028592252605, 546.267305398763, 285.83973342610676, 208.83184728515624, 173.3265512467448, 150.59456974527995, 134.25248311035156, 122.50164867024739, 116.35622235677083, 112.61448102539063, 107.04140088378907, 103.76343618326823, 99.66126768229167, 95.9821802360026, 94.33911462320964, 91.18894970499674, 88.02515171468099, 84.88403221150716, 83.3407439436849, 81.36441092081705, 79.31362923502604, 78.35122577555339, 76.03748635701497, 73.95446583658854, 72.45813270914714, 70.24104186238607, 69.9657667972819, 66.68204318888347, 65.17111615193684, 64.77353048421224, 61.88393656494141, 61.30457855102539, 59.284649084472655, 57.61360815063477, 56.9302004699707, 55.20521035746256, 54.72456991923014, 54.28219326944987, 53.1172882039388, 51.10087702718099, 49.87973960306803, 51.0055470296224, 49.062449031982425, 48.737331572672524, 47.79843918273926, 47.24748483378092, 47.339593358357746], 'val_loss': [13465.639988164063, 2914.677248388672, 2020.126730966797, 859.7517159277344, 348.0061827978516, 249.31306837890625, 183.03603970703125, 168.99719024414063, 155.38307416259767, 132.5958532861328, 110.82461915039063, 114.6704401586914, 103.28105216674804, 107.86752922363281, 112.36643611572265, 101.59821448242188, 93.08128172851562, 96.58714697753906, 93.3948866809082, 93.43490611572265, 121.12905253173828, 82.74691334838867, 88.36350126098633, 76.5272463244629, 86.56338880249024, 71.42747706176758, 72.2322742175293, 63.203406217041014, 66.79248375671386, 67.45659999633789, 98.42414228515625, 72.01400031982422, 65.51931469848633, 66.30700104125977, 62.141632520751955, 66.13957465576172, 61.3926603918457, 54.196544558105465, 70.11938990356445, 60.65900964477539, 70.4341594946289, 45.92481479309082, 50.56885232910156, 45.61439246459961, 45.52363805297851, 47.715461157226564, 43.406188577270505, 43.19055959411621, 39.818945159301755, 48.62687154907226], 'final_test_loss': None, 'activation_function': 'relu', 'training_parameters': {'num_epochs': 50, 'batch_size': 128, 'learning_rate': 0.001}}\n"
     ]
    }
   ],
   "source": [
    "print(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ce que l'on a besoin d'enregistrer\n",
    "# - train loss pour chaque epoch\n",
    "# - val loss pour chaque epoch\n",
    "# - temps d'entrainement\n",
    "# - final test loss\n",
    "# - relu ou gelu\n",
    "# - parameters du modèle (dépend du dataset)\n",
    "# - paramètres d'entrainement :\n",
    "    # - nombre d'epochs\n",
    "    # - batch size\n",
    "    # - learning rate\n",
    "\n",
    "\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'final_test_loss': None,\n",
    "    'activation_function': 'relu',\n",
    "    'model_parameters': model.state_dict(),\n",
    "    'training_parameters': {\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
