{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import torch as torch\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from brevage_sales import brevage_preprocessing, Brevage_model\n",
    "from animal10 import animals10_preprocessing, Animals10_model\n",
    "from training_functions import train_model, evaluate_model\n",
    "from mnist import mnist_preprocessing, mnist_model\n",
    "from student_performance import student_model, student_preprocessing\n",
    "from food_price import preprocess, lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Downloading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_datasets = [\"umitka/food-price-inflation\",\n",
    "            \"minahilfatima12328/performance-trends-in-education\",\n",
    "            \"alessiocorrado99/animals10\",\n",
    "            \"sebastianwillmann/beverage-sales\"]\n",
    "data_dir = \"data/\"\n",
    "\n",
    "download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download:\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    for dataset in kaggle_datasets:\n",
    "        if not os.path.exists(os.path.join(data_dir, dataset.split(\"/\")[-1])):    \n",
    "            os.makedirs(os.path.join(data_dir, dataset.split(\"/\")[-1]), exist_ok=True)\n",
    "            !kaggle datasets download -d {dataset} -p {data_dir}/{dataset} --unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(param_dict):\n",
    "\n",
    "    keys = param_dict.keys()\n",
    "    values = param_dict.values()\n",
    "    \n",
    "    for combination_of_values in itertools.product(*values):\n",
    "        yield dict(zip(keys, combination_of_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BREVAGE = True\n",
    "TRAIN_ANIMALS = False # training beaucoup trop long, fonctionnel mais on a pas la puissance necessaire pour le trainter, seulement 7 entrainements fait pour la visualisation\n",
    "TRAIN_MNIST = True\n",
    "TRAIN_STUDENTS = True\n",
    "TRAIN_FOOD = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brevage price forcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brevage_df = pd.read_csv('./data/sebastianwillmann/beverage-sales/synthetic_beverage_sales_data.csv')\n",
    "# on ne garde que 1 000 000 lignes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevage_model_training(brevage_df, learning_rate, num_epochs, batch_size, mode, random_state, use_batch_norm):\n",
    "    torch.manual_seed(random_state)\n",
    "    \n",
    "    brevage_df = brevage_df.copy()\n",
    "    brevage_df = brevage_df.sample(n=1000000, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = brevage_preprocessing(brevage_df,test_size=0.2,val_size=0.2,random_state=random_state)\n",
    "    brevage_model = Brevage_model(train_dataset.count_features(), mode=mode,use_batch_norm = use_batch_norm)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(brevage_model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(brevage_model.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    history = train_model(brevage_model, criterion, optimizer, num_epochs,train_loader, val_loader)\n",
    "    test_results = evaluate_model(brevage_model, test_loader, device=torch.device(\"cpu\"),loss_type = 'mse')\n",
    "    print(test_results)\n",
    "\n",
    "    history['final_test_loss'] = test_results\n",
    "    \n",
    "    history['dataset'] = 'brevage'\n",
    "    history['random_state'] = random_state\n",
    "    return history, brevage_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brevage_model_param = {\n",
    "    'mode' : ['relu','gelu'],\n",
    "    'batch_size' : [64,2048],\n",
    "    'random_state' : [1,2,3],\n",
    "    'use_batch_norm' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_BREVAGE:\n",
    "    histories = []       \n",
    "    for param in grid_search(brevage_model_param):\n",
    "        hist, brevage_model_ = brevage_model_training(brevage_df, learning_rate=0.001, num_epochs=100, batch_size=param['batch_size'], mode=param['mode'], random_state=param['random_state'], use_batch_norm=param['use_batch_norm'])\n",
    "        histories.append(hist)\n",
    "    json.dump(histories, open('results/brevage_histories.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animals prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_path = \"data/alessiocorrado99/animals10/raw-img\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animals_model_training(animals_path, learning_rate, num_epochs, batch_size, mode, random_state, use_batch_norm):\n",
    "    torch.manual_seed(random_state)\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset, class_to_idx, idx_to_class = animals10_preprocessing(animals_path, test_size=0.2, val_size=0.2, image_size=128, random_state=random_state, subset=0.5)\n",
    "    animal_model = Animals10_model(num_classes=len(class_to_idx), mode=mode,use_batch_norm=use_batch_norm).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(animal_model.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    history = train_model(animal_model, criterion, optimizer, num_epochs,train_loader, val_loader, device)\n",
    "    test_results = evaluate_model(animal_model, test_loader, device, loss_type = 'cross_entropy')\n",
    "    history['final_test_loss'] = test_results\n",
    "    history['random_state'] = random_state\n",
    "\n",
    "    history['dataset'] = 'animals'\n",
    "    return history, animal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_model_param = {\n",
    "    'mode' : ['relu','gelu'],\n",
    "    'batch_size' : [128,1024],\n",
    "    'random_state' : [1,2,3],\n",
    "    'use_batch_norm' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_ANIMALS:\n",
    "    histories = []       \n",
    "    for param in grid_search(animals_model_param):\n",
    "        hist, animal_model_ = animals_model_training(animals_path, learning_rate=0.001, num_epochs=30, batch_size=param['batch_size'], mode=param['mode'], random_state=param['random_state'], use_batch_norm=param['use_batch_norm'])\n",
    "        histories.append(hist)\n",
    "    json.dump(histories, open('results/animals_histories.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist download\n",
    "(mnist_X_train_full, mnist_y_train_full), (mnist_X_test, mnist_y_test) = (keras.datasets.mnist.load_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_model_training(mnist_X_train_full, mnist_y_train_full, mnist_X_test, mnist_y_test, learning_rate, num_epochs, batch_size, mode, random_state, use_batch_norm):\n",
    "    torch.manual_seed(random_state)\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset, scaler = mnist_preprocessing(mnist_X_train_full, mnist_y_train_full, mnist_X_test, mnist_y_test, val_size=0.2, random_state=random_state)\n",
    "    mnist_model_ = mnist_model(mode=mode, use_batch_norm=use_batch_norm).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(mnist_model_.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    history = train_model(mnist_model_, criterion, optimizer, num_epochs,train_loader, val_loader, device)\n",
    "    test_results = evaluate_model(mnist_model_, test_loader, device, loss_type = 'cross_entropy')\n",
    "    history['final_test_loss'] = test_results\n",
    "    history['random_state'] = random_state\n",
    "\n",
    "    history['dataset'] = 'mnist'\n",
    "    return history, mnist_model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model_param = {\n",
    "    'mode' : ['relu','gelu'],\n",
    "    'batch_size' : [64,1024],\n",
    "    'random_state' : [1,2,3],\n",
    "    'use_batch_norm' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MNIST:\n",
    "    histories = []       \n",
    "    for param in grid_search(mnist_model_param):\n",
    "        hist, mnist_model_ = mnist_model_training(mnist_X_train_full, mnist_y_train_full, mnist_X_test, mnist_y_test, learning_rate=0.001, num_epochs=40, batch_size=param['batch_size'], mode=param['mode'], random_state=param['random_state'], use_batch_norm=param['use_batch_norm'])\n",
    "        histories.append(hist)\n",
    "    json.dump(histories, open('results/mnist_histories.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Grade Forcasting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_df = pd.read_csv('./data/minahilfatima12328/performance-trends-in-education/StudentPerformanceFactors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def student_model_training(student_df, learning_rate, num_epochs, batch_size, mode, random_state, use_batch_norm):\n",
    "    torch.manual_seed(random_state)\n",
    "    \n",
    " \n",
    "    train_dataset, val_dataset, test_dataset, scaler_X, scaler_y = student_preprocessing(student_df, val_size=0.2, test_size=0.2, random_state=random_state)\n",
    "    input_size = train_dataset.tensors[0].shape[1]\n",
    "    student_model_ = student_model(input_dim=input_size, mode=mode, use_batch_norm=use_batch_norm).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(student_model_.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    history = train_model(student_model_, criterion, optimizer, num_epochs,train_loader, val_loader, device)\n",
    "    test_results = evaluate_model(student_model_, test_loader, device,loss_type='mse')\n",
    "    history['final_test_loss'] = test_results\n",
    "    history['dataset'] = 'student'\n",
    "    history['random_state'] = random_state\n",
    "\n",
    "    return history, student_model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model_param = {\n",
    "    'mode' : ['relu','gelu'],\n",
    "    'batch_size' : [32,1024],\n",
    "    'random_state' : [1,2,3],\n",
    "    'use_batch_norm' : [True, False]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_STUDENTS:\n",
    "    histories = []       \n",
    "    for param in grid_search(student_model_param):\n",
    "        hist, student_model_ = student_model_training(student_df, learning_rate=0.001, num_epochs=100, batch_size=param['batch_size'], mode=param['mode'], random_state=param['random_state'], use_batch_norm=param['use_batch_norm'])\n",
    "        histories.append(hist)\n",
    "    json.dump(histories, open('results/student_histories.json', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Food price inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation_df = pd.read_csv('data/umitka/food-price-inflation/food_price_inflation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_price_model_training(inflation_df, learning_rate, num_epochs, batch_size, mode, random_state, use_batch_norm):\n",
    "    torch.manual_seed(random_state)\n",
    "    \n",
    "    train_set, val_set, test_set, scaler_X, scaler_y = preprocess(\n",
    "        inflation_df, \n",
    "        split_ratio_train_test=0.8, \n",
    "        split_ratio_train_valid=0.8, device=device)\n",
    "    input_size = train_set.tensors[0].shape[2]\n",
    "    \n",
    "    inflation_model = lstm(input_size=input_size, mode = mode,use_batch_norm=use_batch_norm).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(inflation_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "    history = train_model(inflation_model, criterion, optimizer, num_epochs,train_loader, val_loader,device)\n",
    "    test_results = evaluate_model(inflation_model, test_loader, device, loss_type= 'mse')\n",
    "    history['final_test_loss'] = test_results\n",
    "    history['dataset'] = 'food_price'\n",
    "    history['random_state'] = random_state\n",
    "\n",
    "    return history, inflation_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_price_model_param = {\n",
    "    'mode' : ['relu','gelu'],\n",
    "    'batch_size' : [32,1024],\n",
    "    'random_state' : [1,2,3],\n",
    "    'use_batch_norm' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_FOOD:\n",
    "    histories = []\n",
    "    for param in grid_search(food_price_model_param):\n",
    "        hist, inflation_model_ = food_price_model_training(inflation_df, learning_rate=0.001, num_epochs=100, batch_size=param['batch_size'], mode=param['mode'], random_state=param['random_state'], use_batch_norm=param['use_batch_norm'])\n",
    "        histories.append(hist)\n",
    "    json.dump(histories, open('results/food_price_histories.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
